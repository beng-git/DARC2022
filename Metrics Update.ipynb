{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4e9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ccb3e",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Section1: Pretreatment of the data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844bbc56",
   "metadata": {},
   "source": [
    "## First Dataframe corresponds to the original Dataset (34551849  records in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202c53ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:16</td>\n",
       "      <td>4.870147</td>\n",
       "      <td>45.772140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:48</td>\n",
       "      <td>4.870218</td>\n",
       "      <td>45.772095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:49</td>\n",
       "      <td>4.870210</td>\n",
       "      <td>45.772072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:50</td>\n",
       "      <td>4.870210</td>\n",
       "      <td>45.772072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:52</td>\n",
       "      <td>4.870210</td>\n",
       "      <td>45.772072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551844</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 16:23:21</td>\n",
       "      <td>2.343094</td>\n",
       "      <td>48.891650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551845</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 16:23:22</td>\n",
       "      <td>2.343094</td>\n",
       "      <td>48.891650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551846</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 16:23:24</td>\n",
       "      <td>2.343094</td>\n",
       "      <td>48.891649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551847</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 16:23:25</td>\n",
       "      <td>2.343094</td>\n",
       "      <td>48.891649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551848</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 19:29:04</td>\n",
       "      <td>2.343127</td>\n",
       "      <td>48.891772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34551849 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID            DateTime       lat        lon\n",
       "0           1 2015-03-04 00:35:16  4.870147  45.772140\n",
       "1           1 2015-03-04 00:35:48  4.870218  45.772095\n",
       "2           1 2015-03-04 00:35:49  4.870210  45.772072\n",
       "3           1 2015-03-04 00:35:50  4.870210  45.772072\n",
       "4           1 2015-03-04 00:35:52  4.870210  45.772072\n",
       "...       ...                 ...       ...        ...\n",
       "34551844  110 2015-03-12 16:23:21  2.343094  48.891650\n",
       "34551845  110 2015-03-12 16:23:22  2.343094  48.891650\n",
       "34551846  110 2015-03-12 16:23:24  2.343094  48.891649\n",
       "34551847  110 2015-03-12 16:23:25  2.343094  48.891649\n",
       "34551848  110 2015-03-12 19:29:04  2.343127  48.891772\n",
       "\n",
       "[34551849 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = pd.read_csv('original_file.csv',sep='\\t',header=None, names=['ID','DateTime','lon','lat'])\n",
    "original_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31744288",
   "metadata": {},
   "source": [
    "## We will need the original number of records as parameter for some of the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ad6c516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34551849"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_original_lines = len(original_data)\n",
    "nb_original_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cda84d",
   "metadata": {},
   "source": [
    "## Second Dataframe corresponds to the anonymized Dataset WITHOUT the records marked as 'DEL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e74da269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>404</td>\n",
       "      <td>2015-03-04 00:35:16</td>\n",
       "      <td>4.888</td>\n",
       "      <td>45.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>404</td>\n",
       "      <td>2015-03-04 00:35:50</td>\n",
       "      <td>4.867</td>\n",
       "      <td>45.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>404</td>\n",
       "      <td>2015-03-04 00:35:52</td>\n",
       "      <td>4.879</td>\n",
       "      <td>45.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>404</td>\n",
       "      <td>2015-03-04 00:35:55</td>\n",
       "      <td>4.873</td>\n",
       "      <td>45.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>404</td>\n",
       "      <td>2015-03-04 00:35:56</td>\n",
       "      <td>4.871</td>\n",
       "      <td>45.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551844</th>\n",
       "      <td>799</td>\n",
       "      <td>2015-03-12 16:23:21</td>\n",
       "      <td>4.872</td>\n",
       "      <td>45.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551845</th>\n",
       "      <td>799</td>\n",
       "      <td>2015-03-12 16:23:22</td>\n",
       "      <td>4.882</td>\n",
       "      <td>45.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551846</th>\n",
       "      <td>799</td>\n",
       "      <td>2015-03-12 16:23:24</td>\n",
       "      <td>4.873</td>\n",
       "      <td>45.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551847</th>\n",
       "      <td>799</td>\n",
       "      <td>2015-03-12 16:23:25</td>\n",
       "      <td>4.874</td>\n",
       "      <td>45.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551848</th>\n",
       "      <td>799</td>\n",
       "      <td>2015-03-12 19:29:04</td>\n",
       "      <td>4.874</td>\n",
       "      <td>45.785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21544620 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID            DateTime    lat     lon\n",
       "0         404 2015-03-04 00:35:16  4.888  45.740\n",
       "3         404 2015-03-04 00:35:50  4.867  45.750\n",
       "4         404 2015-03-04 00:35:52  4.879  45.786\n",
       "6         404 2015-03-04 00:35:55  4.873  45.785\n",
       "7         404 2015-03-04 00:35:56  4.871  45.784\n",
       "...       ...                 ...    ...     ...\n",
       "34551844  799 2015-03-12 16:23:21  4.872  45.783\n",
       "34551845  799 2015-03-12 16:23:22  4.882  45.784\n",
       "34551846  799 2015-03-12 16:23:24  4.873  45.785\n",
       "34551847  799 2015-03-12 16:23:25  4.874  45.784\n",
       "34551848  799 2015-03-12 19:29:04  4.874  45.785\n",
       "\n",
       "[21544620 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anon_data = pd.read_csv('anon_data.csv',sep='\\t',header=None, names=['ID','DateTime','lat','lon'])\n",
    "anon_data = anon_data.loc[anon_data.ID !='DEL ']\n",
    "anon_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59337921",
   "metadata": {},
   "source": [
    "## Third Dataframe corresponds to the original dataframe except the records that were 'DEL' in the anonymized dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87bee1",
   "metadata": {},
   "source": [
    "### You should notice that the number of records in df_original_without_DEL and in anon_data should be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e8f2371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:16</td>\n",
       "      <td>4.870147</td>\n",
       "      <td>45.772140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:50</td>\n",
       "      <td>4.870210</td>\n",
       "      <td>45.772072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:52</td>\n",
       "      <td>4.870210</td>\n",
       "      <td>45.772072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:55</td>\n",
       "      <td>4.870210</td>\n",
       "      <td>45.772072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:56</td>\n",
       "      <td>4.870210</td>\n",
       "      <td>45.772072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551844</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 16:23:21</td>\n",
       "      <td>2.343094</td>\n",
       "      <td>48.891650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551845</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 16:23:22</td>\n",
       "      <td>2.343094</td>\n",
       "      <td>48.891650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551846</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 16:23:24</td>\n",
       "      <td>2.343094</td>\n",
       "      <td>48.891649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551847</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 16:23:25</td>\n",
       "      <td>2.343094</td>\n",
       "      <td>48.891649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551848</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 19:29:04</td>\n",
       "      <td>2.343127</td>\n",
       "      <td>48.891772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21544620 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID            DateTime       lat        lon\n",
       "0           1 2015-03-04 00:35:16  4.870147  45.772140\n",
       "3           1 2015-03-04 00:35:50  4.870210  45.772072\n",
       "4           1 2015-03-04 00:35:52  4.870210  45.772072\n",
       "6           1 2015-03-04 00:35:55  4.870210  45.772072\n",
       "7           1 2015-03-04 00:35:56  4.870210  45.772072\n",
       "...       ...                 ...       ...        ...\n",
       "34551844  110 2015-03-12 16:23:21  2.343094  48.891650\n",
       "34551845  110 2015-03-12 16:23:22  2.343094  48.891650\n",
       "34551846  110 2015-03-12 16:23:24  2.343094  48.891649\n",
       "34551847  110 2015-03-12 16:23:25  2.343094  48.891649\n",
       "34551848  110 2015-03-12 19:29:04  2.343127  48.891772\n",
       "\n",
       "[21544620 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original_without_DEL = original_data.loc[anon_data.index]\n",
    "df_original_without_DEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ff5af",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Section 2: The Metrics</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa02f2a",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">The Metrics [\"utility_tuile\", \"utility_POI\", \"utility_meet\"]: require the original df without removing the corresponding 'DEL' record in the anonymized dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a365b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def POI_util(df_anon, df_original):\n",
    "    #Global variables\n",
    "    score = 0\n",
    "    size = 2\n",
    "    values = ['NIGHT', 'NIGHT','WORK', 'WEEKEND']\n",
    "    df_orig = df_original.copy()\n",
    "    df_anon = df_anon.copy()\n",
    "    \n",
    "    if(len(df_anon)!=0):\n",
    "    \n",
    "        df_orig.rename(columns={'id':'ID', 'date':'DateTime', 'latitude':'lat', 'longitude':'lon'}, inplace=True)\n",
    "        df_anon.rename(columns={'id':'ID', 'date':'DateTime', 'latitude':'lat', 'longitude':'lon'}, inplace=True)\n",
    "\n",
    "        df_orig['DateTime']= df_orig['DateTime'].astype('datetime64[ns]')\n",
    "        df_orig['ID']= df_orig['ID'].astype('string')\n",
    "        df_orig['lat']= df_orig['lat'].astype('float64')\n",
    "        df_orig['lon']= df_orig['lon'].astype('float64')\n",
    "\n",
    "        df_anon['DateTime']= df_anon['DateTime'].astype('datetime64[ns]')\n",
    "        df_anon['ID']= df_anon['ID'].astype('string')\n",
    "        df_anon['lat']= df_anon['lat'].astype('float64')\n",
    "        df_anon['lon']= df_anon['lon'].astype('float64')\n",
    "        #df_anon['ID']=df_orig['ID']\n",
    "        df_anon['ID']= df_orig.loc[df_anon.index.intersection(df_orig.index),'ID']\n",
    "\n",
    "        #Pre-treatment of original dataframe\n",
    "        df_orig['lat']=df_orig['lat'].round(size)\n",
    "        df_orig['lon']=df_orig['lon'].round(size)\n",
    "        df_orig['Hour'] = df_orig.loc[:,'DateTime'].dt.hour\n",
    "        df_orig['Day'] = df_orig.loc[:,'DateTime'].dt.day\n",
    "        df_orig['Month'] = df_orig.loc[:,'DateTime'].dt.month\n",
    "        df_orig['Week'] = df_orig.loc[:,'DateTime'].dt.isocalendar().week\n",
    "        df_orig['DayOfTheWeek'] = df_orig.loc[:,'DateTime'].dt.dayofweek\n",
    "        df_orig.sort_values(by=['ID', 'DateTime'], inplace=True)\n",
    "        df_orig.reset_index(drop=True, inplace=True)\n",
    "        df_orig['DatetimeIndex'] = np.select(conditions(df_orig), values, 'RegularTime')\n",
    "        df_orig['time_spent']=0\n",
    "\n",
    "        df_orig['Index_of_POI'] = df_orig['ID'] + '-' + df_orig['Day'].astype('string') + '-' + df_orig['Week'].astype('string') + '-' + df_orig['lat'].astype('string') + '-' + df_orig['lon'].astype('string') + '-' + df_orig['DatetimeIndex'].astype('string')\n",
    "        df_orig['Index_of_POI_shifted_backward'] = df_orig['Index_of_POI'].shift(-1)\n",
    "        df_orig['Index_of_POI_shifted_forward'] = df_orig['Index_of_POI'].shift(+1)\n",
    "        df_orig.loc[0,'Index_of_POI_shifted_forward']='0'\n",
    "        df_orig.loc[len(df_orig)-1,'Index_of_POI_shifted_backward']='0'\n",
    "        df_orig['start_time'] = df_orig.loc[~(df_orig['Index_of_POI']==df_orig['Index_of_POI_shifted_forward']), 'DateTime']\n",
    "        df_orig.fillna(method=\"ffill\", inplace=True)\n",
    "        df_orig['time_spent'] = (df_orig['DateTime'] - df_orig['start_time'])\n",
    "\n",
    "        #Getting the POI\n",
    "        df_orig2 = df_orig.loc[~(df_orig['Index_of_POI_shifted_backward']==df_orig['Index_of_POI']),['ID', 'lat', 'lon', 'Week', 'DatetimeIndex', 'time_spent']].groupby(by=['ID', 'lat', 'lon', 'Week', 'DatetimeIndex']).sum().reset_index()\n",
    "        df_orig2 = df_orig2.sort_values(by=['ID', 'Week', 'time_spent',  'DatetimeIndex'], ascending=[True, True, False, False]).reset_index(drop=True)\n",
    "        df_orig2 = df_orig2.groupby(by=['ID', 'Week', 'DatetimeIndex']).head(1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "        #Pre-treatment of anonymized dataframe\n",
    "\n",
    "        df_anon['lat']=df_anon['lat'].round(size)\n",
    "        df_anon['lon']=df_anon['lon'].round(size)\n",
    "        df_anon['Hour'] = df_anon.loc[:,'DateTime'].dt.hour\n",
    "        df_anon['Day'] = df_anon.loc[:,'DateTime'].dt.day\n",
    "        df_anon['Month'] = df_anon.loc[:,'DateTime'].dt.month\n",
    "        df_anon['Week'] = df_anon.loc[:,'DateTime'].dt.isocalendar().week\n",
    "        df_anon['DayOfTheWeek'] = df_anon.loc[:,'DateTime'].dt.dayofweek\n",
    "        df_anon.sort_values(by=['ID', 'DateTime'], inplace=True)\n",
    "        df_anon.reset_index(drop=True, inplace=True)\n",
    "        df_anon['DatetimeIndex'] = np.select(conditions(df_anon), values, 'RegularTime')\n",
    "        df_anon['time_spent']=0\n",
    "\n",
    "        df_anon['Index_of_POI'] = df_anon['ID'] + '-' + df_anon['Day'].astype('string') + '-' + df_anon['Week'].astype('string') + '-' + df_anon['lat'].astype('string') + '-' + df_anon['lon'].astype('string') + '-' + df_anon['DatetimeIndex'].astype('string')\n",
    "        df_anon['Index_of_POI_shifted_backward'] = df_anon['Index_of_POI'].shift(-1)\n",
    "        df_anon['Index_of_POI_shifted_forward'] = df_anon['Index_of_POI'].shift(+1)\n",
    "        df_anon.loc[0,'Index_of_POI_shifted_forward']='0'\n",
    "        df_anon.loc[len(df_anon)-1,'Index_of_POI_shifted_backward']='0'\n",
    "        df_anon['start_time'] = df_anon.loc[~(df_anon['Index_of_POI']==df_anon['Index_of_POI_shifted_forward']), 'DateTime']\n",
    "        df_anon.fillna(method=\"ffill\", inplace=True)\n",
    "        df_anon['time_spent'] = (df_anon['DateTime'] - df_anon['start_time'])\n",
    "\n",
    "        df_anon2 = df_anon.loc[~(df_anon['Index_of_POI_shifted_backward']==df_anon['Index_of_POI']),['ID', 'lat', 'lon', 'Week', 'DatetimeIndex', 'time_spent']].groupby(by=['ID', 'lat', 'lon', 'Week', 'DatetimeIndex']).sum().reset_index()\n",
    "        df_anon2 = df_anon2.sort_values(by=['ID', 'Week', 'time_spent',  'DatetimeIndex'], ascending=[True, True, False, False]).reset_index(drop=True)\n",
    "\n",
    "        #Comparing the time spent in POI between original and anonymized dataset\n",
    "        df_orig2 = df_orig2.loc[~(df_orig2.DatetimeIndex =='RegularTime')]\n",
    "        left_join_df = pd.merge(df_orig2, df_anon2, on=['ID','lat','lon','Week','DatetimeIndex'], how='left')\n",
    "\n",
    "        left_join_df['time_spent_y'] = left_join_df['time_spent_y'].fillna(pd.Timedelta(seconds=0))\n",
    "        left_join_df['diff_time_spent'] = abs( left_join_df['time_spent_y'].dt.total_seconds() - left_join_df['time_spent_x'].dt.total_seconds() )\n",
    "        left_join_df['time_spent_x'] = left_join_df['time_spent_x'].dt.total_seconds()\n",
    "        \n",
    "        #Calculating the scrore\n",
    "        score = 1- (left_join_df['diff_time_spent'].sum()/left_join_df['time_spent_x'].sum())\n",
    "    return score\n",
    "\n",
    "def conditions(df):\n",
    "    return [\n",
    "        (df['DayOfTheWeek'] < 4) & (df['Hour']>=22) & (df['Hour']<=23), \n",
    "        (df['DayOfTheWeek'] < 4) & (df['Hour']>=0) & (df['Hour']<=6),\n",
    "        (df['DayOfTheWeek'] < 4) & (df['Hour']>=9) & (df['Hour']<=17),\n",
    "        (df['DayOfTheWeek'] >= 4) & (df['Hour']>=10) & (df['Hour']<=18)\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddfb191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice the argument we are using the original_data with the anonymized_data (different dataframe sizes)\n",
    "print(\"POI Utility Score =\",POI_util(anon_data, original_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160baa2f",
   "metadata": {},
   "source": [
    "### nothing has changed in the meet_utility metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9d16d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meet_utility(df_anon, df_original):\n",
    "    #Define global variable\n",
    "    size = 2\n",
    "    pt = 0.1\n",
    "\n",
    "    df = df_anon.copy()\n",
    "    df_orig = df_original.copy()\n",
    "\n",
    "    # Converting longitude and latitude as float \n",
    "    df = df.astype({'lon': 'float64', 'lat': 'float64'})\n",
    "    df_orig = df_orig.astype({'lon': 'float64', 'lat': 'float64'})\n",
    "\n",
    "    # Round lat,long with size\n",
    "    df['lat'] = df['lat'].round(size)\n",
    "    df['lon'] = df['lon'].round(size)\n",
    "    df_orig['lat'] = df_orig['lat'].round(size)\n",
    "    df_orig['lon'] = df_orig['lon'].round(size)\n",
    "\n",
    "    # get all unique positions and sort them by most visited\n",
    "    df = df.groupby(['lat','lon']).size().reset_index(name='count')\n",
    "    df_orig = df_orig.groupby(['lat','lon']).size().reset_index(name='count')\n",
    "    df = df.sort_values(by=['count'])\n",
    "    df_orig = df_orig.sort_values(by=['count'])\n",
    "\n",
    "    # Only keep top % cells\n",
    "    nb_cellules = int(len(df_orig)*pt)\n",
    "    df = df.head(nb_cellules)\n",
    "    df_orig = df_orig.head(nb_cellules)\n",
    "\n",
    "    # left join and compare cells\n",
    "    df = pd.merge(df_orig, df, on=['lat', 'lon'], how='left')\n",
    "    \n",
    "    score = df['count_y'].notnull().sum()\n",
    "    return score / nb_cellules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a80d6d",
   "metadata": {},
   "source": [
    "#### notice the argument we are using the original_data with the anonymized_data (different dataframe sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be564d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Meet Utility score =\", meet_utility(anon_data, original_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b986a23e",
   "metadata": {},
   "source": [
    "### nothing has changed in the tuile_utility metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f13d5b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuile_utility(df_anon, df_original):\n",
    "    size = 2\n",
    "    df = df_anon.copy()\n",
    "    df_orig = df_original.copy()\n",
    "    \n",
    "    # Converting longitude and latitude as float \n",
    "    df = df.astype({'lon': 'float64', 'lat': 'float64', 'ID': 'string' })\n",
    "    df_orig = df_orig.astype({'lon': 'float64', 'lat': 'float64', 'ID': 'string'})\n",
    "\n",
    "    # Round lat,long with size\n",
    "    df['lat'] = df['lat'].round(size)\n",
    "    df['lon'] = df['lon'].round(size)\n",
    "    df_orig['lat'] = df_orig['lat'].round(size)\n",
    "    df_orig['lon'] = df_orig['lon'].round(size)\n",
    "\n",
    "    # Group each position for ids and retrieve the count of unique position\n",
    "    df = df.groupby(['ID','lat','lon']).size().reset_index(name='count')\n",
    "    df_orig = df_orig.groupby(['ID','lat','lon']).size().reset_index(name='count')\n",
    "    df = df.groupby(['ID']).size().reset_index(name='count')\n",
    "    df_orig = df_orig.groupby(['ID']).size().reset_index(name='count')\n",
    "\n",
    "    df = pd.merge(df_orig, df, on=['ID'], how='left')\n",
    "    df['score'] = df.apply(createScore, axis=1)\n",
    "    score = df['score'].sum()\n",
    "    return score / len(df)\n",
    "\n",
    "def createScore(row):\n",
    "    if pd.isnull(row['count_x']) or pd.isnull(row['count_y']):\n",
    "        score = 0\n",
    "    elif row['count_x'] > row['count_y']:\n",
    "        score = row['count_y'] / row['count_x']\n",
    "    else:\n",
    "        score = row['count_x'] / row['count_y']\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4653db",
   "metadata": {},
   "source": [
    "### notice the argument we are using the original_data with the anonymized_data (different dataframe sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuile Utility score =\", tuile_utility(anon_data, original_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730cdf2c",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">The Metrics [\"hour_utility\", \"date_utility\", \"distance_util\"]: compare the datasets on only the records that were not deleted. yet to compute the mean of the score of each row we divide by the \"nb_original_lines\" which will take into consideration a utility =0 for the records that were deleted in the numerator</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8838c4",
   "metadata": {},
   "source": [
    "### hour_utility Update: to take into consideration the DEL records with score =0 \n",
    "We divide by the original number of records thus making date_util = 0 for the 'DEL' records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1425863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_utility(df_anon, df_original, nb_original_lines):\n",
    "    df_orig = df_original.copy()\n",
    "    df_anon = df_anon.copy()\n",
    "\n",
    "    df = pd.DataFrame({ 'df_hour': df_anon['DateTime'].dt.hour, 'df_origin_hour': df_orig['DateTime'].dt.hour })\n",
    "    #Chaque ligne vaut 1 point\n",
    "    #Une fraction de point eguale a 1/24 est enlevée à chaque heure d'écart\n",
    "    df['hour_util'] = 1- abs(df['df_hour'] - df['df_origin_hour'])/24\n",
    "    # le score finale est la moyenne d'ecart d'heures sur tous les points detecter\n",
    "    score_hour_utility = df[\"hour_util\"].sum()/nb_original_lines\n",
    "    \n",
    "    return score_hour_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice the argument we are using the df_original_without_DEL with the anonymized_data (same dataframe sizes)\n",
    "print(\"Hour Utility score =\", hour_utility(anon_data, df_original_without_DEL, nb_original_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5633d9ea",
   "metadata": {},
   "source": [
    "### date_utility Update: to take into consideration the DEL records with score =0 \n",
    "We divide by the original number of records thus making date_util = 0 for the 'DEL' records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_utility(df_anon, df_original, nb_original_lines):\n",
    "    df_orig = df_original.copy()\n",
    "    df_anon = df_anon.copy()\n",
    "#     df_orig.reset_index(drop=True, inplace=True)\n",
    "#     df_anon.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df_date_utility = pd.DataFrame({ 'DayOfTheWeek_orig': df_orig['DateTime'].dt.dayofweek, 'DayOfTheWeek_anon': df_anon['DateTime'].dt.dayofweek, 'Week_orig':df_orig['DateTime'].dt.isocalendar().week, 'Week_anon': df_anon['DateTime'].dt.isocalendar().week })\n",
    "    df_date_utility['DiffDate'] = abs(df_date_utility['DayOfTheWeek_orig']-df_date_utility['DayOfTheWeek_anon'])\n",
    "    #pour tout changement de semaine l'utilite doit etre 0 \n",
    "    df_date_utility.loc[~(df_date_utility['Week_orig']==df_date_utility['Week_anon']),'DiffDate']=7\n",
    "    df_date_utility['date_util']= 1- df_date_utility['DiffDate']/7\n",
    "    score = df_date_utility[\"date_util\"].sum()/nb_original_lines\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc2fcf5",
   "metadata": {},
   "source": [
    "#### notice the argument we are using the df_original_without_DEL with the anonymized_data (same dataframe sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12252245",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Date Utility score =\",Date_utility(anon_data, df_original_without_DEL, nb_original_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12324352",
   "metadata": {},
   "source": [
    "### distance_utility Update: to take into consideration the DEL records with score =0 \n",
    "We set: </br> 'Distance_Accuracy' = 1 (for any record whose Haversine distance <1 km) </br>\n",
    "       'Distance_Accuracy' = 1/Haversine_distance (for the records where the distance > 1 km)</br>\n",
    "       The score is the sum of the 'Distance_Accuracy' but divided by the original number of records (thus considering their     distance _accuracy =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5c4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_utility(df_anon, df_original, nb_original_lines):\n",
    "\n",
    "    df_orig = df_original.copy()\n",
    "    df_anon = df_anon.copy()\n",
    "#     df_orig.reset_index(drop=True, inplace=True)\n",
    "#     df_anon.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df_anon.rename(columns={'ID':'ID_ano', 'DateTime':'DateTime_ano', 'lat':'lat_ano', 'lon':'lon_ano'}, inplace = True)\n",
    "    df = pd.concat([df_orig.reset_index(drop=True),df_anon.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    #Haversine distance\n",
    "    to_radians = np.pi /180\n",
    "    R = 6371.009 #en km\n",
    "    #a=np.sin(((df.lat*to_radians-df.lat_ano*to_radians)/2)**2) + np.sin((((df.lon*to_radians-df.lon_ano*to_radians)/2)**2))*np.cos(df.lat*to_radians)*np.cos(df.lat_ano*to_radians)\n",
    "    a = np.sin(((df.lat*to_radians-df.lat_ano*to_radians)/2))**2 + (np.sin((((df.lon*to_radians-df.lon_ano*to_radians)/2)))**(2))*np.cos(df.lat*to_radians)*np.cos(df.lat_ano*to_radians)\n",
    "    b = np.sqrt(a)\n",
    "    df['Haversine_Distance']= 2 * R * np.arcsin(b)\n",
    "    \n",
    "    df['Distance_Accuracy'] = 1 #cette valeur reste valide pour tout changement dans un rayon de 1Km\n",
    "    df.loc[df['Haversine_Distance'] >1 , 'Distance_Accuracy'] = 1/df['Haversine_Distance']\n",
    "    score = df[\"Distance_Accuracy\"].sum()/nb_original_lines\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba95d111",
   "metadata": {},
   "source": [
    "#### notice the argument we are using the df_original_without_DEL with the anonymized_data (same dataframe sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice the argument we are using the df_original_without_DEL with the anonymized_data (same dataframe sizes)\n",
    "print(\"Distance Utility score =\",distance_utility(anon_data, df_original_without_DEL, nb_original_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e6504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
