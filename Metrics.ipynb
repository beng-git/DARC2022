{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb4e9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "326ea769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_data = pd.read_csv(\"original_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e855875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anon_data = pd.read_csv(r\"anonimized_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1425863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_utility(df_anon, df_original):\n",
    "    df_orig = df_original.copy()\n",
    "    df_anon = df_anon.copy()\n",
    "\n",
    "    df = pd.DataFrame({ 'df_hour': df_anon['DateTime'].dt.hour, 'df_origin_hour': df_orig['DateTime'].dt.hour })\n",
    "    #Chaque ligne vaut 1 point\n",
    "    #Une fraction de point eguale a 1/24 est enlevée à chaque heure d'écart\n",
    "    df['hour_util'] = 1- abs(df['df_hour'] - df['df_origin_hour'])/24\n",
    "    # le score finale est la moyenne d'ecart d'heures sur tous les points detecter\n",
    "    score_hour_utility = df[\"hour_util\"].sum()/len(df_orig)\n",
    "    \n",
    "    return score_hour_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d9312e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_utility(df_anon, df_original):\n",
    "    df_orig = df_original.copy()\n",
    "    df_anon = df_anon.copy()\n",
    "\n",
    "    df_date_utility = pd.DataFrame({ 'DayOfTheWeek_orig': df_orig['DateTime'].dt.dayofweek, 'DayOfTheWeek_anon': df_anon['DateTime'].dt.dayofweek, 'Week_orig':df_orig['DateTime'].dt.isocalendar().week, 'Week_anon': df_anon['DateTime'].dt.isocalendar().week })\n",
    "    df_date_utility['DiffDate'] = abs(df_date_utility['DayOfTheWeek_orig']-df_date_utility['DayOfTheWeek_anon'])\n",
    "    #pour tout changement de semaine l'utilite doit etre 0 \n",
    "    df_date_utility.loc[~(df_date_utility['Week_orig']==df_date_utility['Week_anon']),'DiffDate']=7\n",
    "    df_date_utility['date_util']= 1- df_date_utility['DiffDate']/7\n",
    "\n",
    "    score = df_date_utility[\"date_util\"].mean().round(3)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7b1a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_utility(df_anon, df_original):\n",
    "\n",
    "    df_orig = df_original.copy()\n",
    "    df_anon = df_anon.copy()\n",
    "    \n",
    "    df_anon.rename(columns={'ID':'ID_ano', 'DateTime':'DateTime_ano', 'lat':'lat_ano', 'lon':'lon_ano'}, inplace = True)\n",
    "    df = pd.concat([df_orig.reset_index(drop=True),df_anon.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    #Haversine distance\n",
    "    to_radians = np.pi /180\n",
    "    R = 6371.009 #en km\n",
    "    #a=np.sin(((df.lat*to_radians-df.lat_ano*to_radians)/2)**2) + np.sin((((df.lon*to_radians-df.lon_ano*to_radians)/2)**2))*np.cos(df.lat*to_radians)*np.cos(df.lat_ano*to_radians)\n",
    "    a = np.sin(((df.lat*to_radians-df.lat_ano*to_radians)/2))**2 + (np.sin((((df.lon*to_radians-df.lon_ano*to_radians)/2)))**(2))*np.cos(df.lat*to_radians)*np.cos(df.lat_ano*to_radians)\n",
    "    b = np.sqrt(a)\n",
    "    df['Haversine_score']= 2 * R * np.arcsin(b)\n",
    "    if(df[\"Haversine_score\"].mean().round(3)==0):\n",
    "        score = 1\n",
    "    else:\n",
    "        score = (1/(df[\"Haversine_score\"].mean())).round(3)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5c88c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def POI_utility(df_anon, df_original):\n",
    "    #Global variables\n",
    "    size = 2\n",
    "    values = ['NIGHT', 'NIGHT','WORK', 'WEEKEND']\n",
    "    df_orig = df_original.copy()\n",
    "    df_anon = df_anon.copy() #anon_data\n",
    "\n",
    "    df_orig['DateTime']= df_orig['DateTime'].astype('datetime64[ns]')\n",
    "    df_orig['ID']= df_orig['ID'].astype('string')\n",
    "    df_anon['DateTime']= df_anon['DateTime'].astype('datetime64[ns]')\n",
    "    df_anon['ID']= df_anon['ID'].astype('string')\n",
    "\n",
    "    #Pre-treatment of original dataframe\n",
    "    df_orig['lat']=df_orig['lat'].round(size)\n",
    "    df_orig['lon']=df_orig['lon'].round(size)\n",
    "    df_orig['Hour'] = df_orig['DateTime'].dt.hour\n",
    "    df_orig['Day'] = df_orig['DateTime'].dt.day\n",
    "    df_orig['Month'] = df_orig['DateTime'].dt.month\n",
    "    df_orig['Week'] = df_orig['DateTime'].dt.isocalendar().week\n",
    "    df_orig['DayOfTheWeek'] = df_orig['DateTime'].dt.dayofweek\n",
    "    df_orig.sort_values(by=['ID', 'DateTime'], inplace=True)\n",
    "    df_orig.reset_index(drop=True, inplace=True)\n",
    "    df_orig['DatetimeIndex'] = np.select(conditions(df_orig), values, 'RegularTime')\n",
    "    df_orig['time_spent']=0\n",
    "\n",
    "    df_orig['Index_of_POI'] = df_orig['ID'] + '-' + df_orig['Day'].astype('string') + '-' + df_orig['Week'].astype('string') + '-' + df_orig['lat'].astype('string') + '-' + df_orig['lon'].astype('string') + '-' + df_orig['DatetimeIndex'].astype('string')\n",
    "    df_orig['Index_of_POI_shifted_backward'] = df_orig['Index_of_POI'].shift(-1)\n",
    "    df_orig['Index_of_POI_shifted_forward'] = df_orig['Index_of_POI'].shift(+1)\n",
    "    df_orig.loc[0,'Index_of_POI_shifted_forward']='0'\n",
    "    df_orig.loc[len(df_orig)-1,'Index_of_POI_shifted_backward']='0'\n",
    "    df_orig['start_time'] = df_orig.loc[~(df_orig['Index_of_POI']==df_orig['Index_of_POI_shifted_forward']), 'DateTime']\n",
    "    df_orig.fillna(method=\"ffill\", inplace=True) #propagate non-null values forward or backward\n",
    "    df_orig['time_spent'] = (df_orig['DateTime'] - df_orig['start_time'])#.dt.total_seconds()/60\n",
    "\n",
    "    #Getting the POI\n",
    "    df_orig2 = df_orig.loc[~(df_orig['Index_of_POI_shifted_backward']==df_orig['Index_of_POI']),['ID', 'lat', 'lon', 'Week', 'DatetimeIndex', 'time_spent']].groupby(by=['ID', 'lat', 'lon', 'Week', 'DatetimeIndex']).sum().reset_index()\n",
    "    df_orig2 = df_orig2.sort_values(by=['ID', 'Week', 'time_spent',  'DatetimeIndex'], ascending=[True, True, False, False]).reset_index(drop=True)\n",
    "    df_orig2 = df_orig2.groupby(by=['ID', 'Week', 'DatetimeIndex']).head(1).reset_index(drop=True)\n",
    "    \n",
    "    #Pre-treatment of original dataframe\n",
    "    df_anon['ID']=df_orig['ID']\n",
    "    df_anon['lat']=df_anon['lat'].round(size)\n",
    "    df_anon['lon']=df_anon['lon'].round(size)\n",
    "    df_anon['Hour'] = df_anon['DateTime'].dt.hour\n",
    "    df_anon['Day'] = df_anon['DateTime'].dt.day\n",
    "    df_anon['Month'] = df_anon['DateTime'].dt.month\n",
    "    df_anon['Week'] = df_anon['DateTime'].dt.isocalendar().week\n",
    "    df_anon['DayOfTheWeek'] = df_anon['DateTime'].dt.dayofweek\n",
    "    df_anon.sort_values(by=['ID', 'DateTime'], inplace=True)\n",
    "    df_anon.reset_index(drop=True, inplace=True)\n",
    "    df_anon['DatetimeIndex'] = np.select(conditions(df_anon), values, 'RegularTime')\n",
    "    df_anon['time_spent']=0\n",
    "\n",
    "    df_anon['Index_of_POI'] = df_anon['ID'] + '-' + df_anon['Day'].astype('string') + '-' + df_anon['Week'].astype('string') + '-' + df_anon['lat'].astype('string') + '-' + df_anon['lon'].astype('string') + '-' + df_anon['DatetimeIndex'].astype('string')\n",
    "    df_anon['Index_of_POI_shifted_backward'] = df_anon['Index_of_POI'].shift(-1)\n",
    "    df_anon['Index_of_POI_shifted_forward'] = df_anon['Index_of_POI'].shift(+1)\n",
    "    df_anon.loc[0,'Index_of_POI_shifted_forward']='0'\n",
    "    df_anon.loc[len(df_anon)-1,'Index_of_POI_shifted_backward']='0'\n",
    "    \n",
    "    df_anon['start_time'] = df_anon.loc[~(df_anon['Index_of_POI']==df_anon['Index_of_POI_shifted_forward']), 'DateTime']\n",
    "    df_anon.fillna(method=\"ffill\", inplace=True) #propagate non-null values forward or backward\n",
    "    df_anon['time_spent'] = (df_anon['DateTime'] - df_anon['start_time'])#.dt.total_seconds()/60\n",
    "\n",
    "    df_anon2 = df_anon.loc[~(df_anon['Index_of_POI_shifted_backward']==df_anon['Index_of_POI']),['ID', 'lat', 'lon', 'Week', 'DatetimeIndex', 'time_spent']].groupby(by=['ID', 'lat', 'lon', 'Week', 'DatetimeIndex']).sum().reset_index()\n",
    "    \n",
    "    #Comparing the time spent in POI between original and anonymized dataset\n",
    "    df_orig2 = df_orig2.loc[~(df_orig2.DatetimeIndex =='RegularTime')]\n",
    "    left_join_df = pd.merge(df_orig2, df_anon2, on=['ID','lat','lon','Week','DatetimeIndex'], how='left')\n",
    "    \n",
    "    left_join_df['time_spent_y'] = left_join_df['time_spent_y'].fillna(pd.Timedelta(seconds=0))\n",
    "    left_join_df['diff_time_spent'] = abs( left_join_df['time_spent_y'].dt.total_seconds() - left_join_df['time_spent_x'].dt.total_seconds() )\n",
    "    left_join_df['time_spent_x'] = left_join_df['time_spent_x'].dt.total_seconds()\n",
    "    \n",
    "    #Calculating the scrore\n",
    "    score = 1- (left_join_df['diff_time_spent'].sum()/left_join_df['time_spent_x'].sum())\n",
    "    return score\n",
    "\n",
    "def conditions(df):\n",
    "    return [\n",
    "        (df['DayOfTheWeek'] < 4) & (df['Hour']>=22) & (df['Hour']<=23), \n",
    "        (df['DayOfTheWeek'] < 4) & (df['Hour']>=0) & (df['Hour']<=6),\n",
    "        (df['DayOfTheWeek'] < 4) & (df['Hour']>=9) & (df['Hour']<=17),\n",
    "        (df['DayOfTheWeek'] >= 4) & (df['Hour']>=10) & (df['Hour']<=18)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d7d025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meet_utility(df_anon, df_original):\n",
    "    #Define global variable\n",
    "    size = 2\n",
    "    pt = 0.1\n",
    "\n",
    "    df = df_anon.copy()\n",
    "    df_orig = df_original.copy()\n",
    "\n",
    "    # Converting longitude and latitude as float \n",
    "    df = df.astype({'longitude': 'float64', 'latitude': 'float64'})\n",
    "    df_orig = df_orig.astype({'longitude': 'float64', 'latitude': 'float64'})\n",
    "\n",
    "    # Round lat,long with size\n",
    "    df['latitude'] = df['latitude'].round(size)\n",
    "    df['longitude'] = df['longitude'].round(size)\n",
    "    df_orig['latitude'] = df_orig['latitude'].round(size)\n",
    "    df_orig['longitude'] = df_orig['longitude'].round(size)\n",
    "\n",
    "    # get all unique positions and sort them by most visited\n",
    "    df = df.groupby(['latitude','longitude']).size().reset_index(name='count')\n",
    "    df_orig = df_orig.groupby(['latitude','longitude']).size().reset_index(name='count')\n",
    "    df = df.sort_values(by=['count'])\n",
    "    df_orig = df_orig.sort_values(by=['count'])\n",
    "\n",
    "    # Only keep top % cells\n",
    "    nb_cellules = int(len(df_orig)*pt)\n",
    "    df = df.head(nb_cellules)\n",
    "    df_orig = df_orig.head(nb_cellules)\n",
    "\n",
    "    # left join and compare cells\n",
    "    df = pd.merge(df_orig, df, on=['latitude', 'longitude'], how='left')\n",
    "    score = df['count_y'].notnull().sum()\n",
    "\n",
    "    return score / nb_cellules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa7767ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuile_utility(df_anon, df_original):\n",
    "    size = 2\n",
    "    df = df_anon.copy()\n",
    "    df_orig = df_original.copy()\n",
    "    \n",
    "    # Converting longitude and latitude as float \n",
    "    df = df.astype({'longitude': 'float64', 'latitude': 'float64', 'id': 'string' })\n",
    "    df_orig = df_orig.astype({'longitude': 'float64', 'latitude': 'float64', 'id': 'string'})\n",
    "\n",
    "    # Round lat,long with size\n",
    "    df['latitude'] = df['latitude'].round(size)\n",
    "    df['longitude'] = df['longitude'].round(size)\n",
    "    df_orig['latitude'] = df_orig['latitude'].round(size)\n",
    "    df_orig['longitude'] = df_orig['longitude'].round(size)\n",
    "\n",
    "    # Group each position for ids and retrieve the count of unique position\n",
    "    df = df.groupby(['id','latitude','longitude']).size().reset_index(name='count')\n",
    "    df_orig = df_orig.groupby(['id','latitude','longitude']).size().reset_index(name='count')\n",
    "    df = df.groupby(['id']).size().reset_index(name='count')\n",
    "    df_orig = df_orig.groupby(['id']).size().reset_index(name='count')\n",
    "\n",
    "    df = pd.merge(df_orig, df, on=['id'], how='left')\n",
    "    df['score'] = df.apply(createScore, axis=1)\n",
    "    score = df['score'].sum()\n",
    "    return score / len(df)\n",
    "\n",
    "def createScore(row):\n",
    "    if pd.isnull(row['count_x']) or pd.isnull(row['count_y']):\n",
    "        score = 0\n",
    "    elif row['count_x'] > row['count_y']:\n",
    "        score = row['count_y'] / row['count_x']\n",
    "    else:\n",
    "        score = row['count_x'] / row['count_y']\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1591a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
