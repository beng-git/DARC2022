{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4e9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "202c53ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:16</td>\n",
       "      <td>4.870147</td>\n",
       "      <td>45.772140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:48</td>\n",
       "      <td>4.870218</td>\n",
       "      <td>45.772095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:49</td>\n",
       "      <td>4.870210</td>\n",
       "      <td>45.772072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:50</td>\n",
       "      <td>4.870210</td>\n",
       "      <td>45.772072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-04 00:35:52</td>\n",
       "      <td>4.870210</td>\n",
       "      <td>45.772072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551844</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 16:23:21</td>\n",
       "      <td>2.343094</td>\n",
       "      <td>48.891650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551845</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 16:23:22</td>\n",
       "      <td>2.343094</td>\n",
       "      <td>48.891650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551846</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 16:23:24</td>\n",
       "      <td>2.343094</td>\n",
       "      <td>48.891649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551847</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 16:23:25</td>\n",
       "      <td>2.343094</td>\n",
       "      <td>48.891649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551848</th>\n",
       "      <td>110</td>\n",
       "      <td>2015-03-12 19:29:04</td>\n",
       "      <td>2.343127</td>\n",
       "      <td>48.891772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34551849 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID            DateTime       lat        lon\n",
       "0           1 2015-03-04 00:35:16  4.870147  45.772140\n",
       "1           1 2015-03-04 00:35:48  4.870218  45.772095\n",
       "2           1 2015-03-04 00:35:49  4.870210  45.772072\n",
       "3           1 2015-03-04 00:35:50  4.870210  45.772072\n",
       "4           1 2015-03-04 00:35:52  4.870210  45.772072\n",
       "...       ...                 ...       ...        ...\n",
       "34551844  110 2015-03-12 16:23:21  2.343094  48.891650\n",
       "34551845  110 2015-03-12 16:23:22  2.343094  48.891650\n",
       "34551846  110 2015-03-12 16:23:24  2.343094  48.891649\n",
       "34551847  110 2015-03-12 16:23:25  2.343094  48.891649\n",
       "34551848  110 2015-03-12 19:29:04  2.343127  48.891772\n",
       "\n",
       "[34551849 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = pd.read_csv(\"original_file.csv\")\n",
    "original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25588cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>958</td>\n",
       "      <td>2015-03-18 18:00:00</td>\n",
       "      <td>4.888</td>\n",
       "      <td>45.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEL</td>\n",
       "      <td>2015-03-04 18:00:00</td>\n",
       "      <td>-0.571</td>\n",
       "      <td>44.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEL</td>\n",
       "      <td>2015-03-11 02:00:00</td>\n",
       "      <td>5.279</td>\n",
       "      <td>45.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>404</td>\n",
       "      <td>2015-04-08 14:00:00</td>\n",
       "      <td>4.867</td>\n",
       "      <td>45.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>488</td>\n",
       "      <td>2015-03-25 14:00:00</td>\n",
       "      <td>4.879</td>\n",
       "      <td>45.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551844</th>\n",
       "      <td>229</td>\n",
       "      <td>2015-03-25 10:00:00</td>\n",
       "      <td>4.872</td>\n",
       "      <td>45.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551845</th>\n",
       "      <td>424</td>\n",
       "      <td>2015-04-08 10:00:00</td>\n",
       "      <td>4.882</td>\n",
       "      <td>45.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551846</th>\n",
       "      <td>719</td>\n",
       "      <td>2015-04-08 18:00:00</td>\n",
       "      <td>4.873</td>\n",
       "      <td>45.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551847</th>\n",
       "      <td>335</td>\n",
       "      <td>2015-03-25 14:00:00</td>\n",
       "      <td>4.874</td>\n",
       "      <td>45.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34551848</th>\n",
       "      <td>719</td>\n",
       "      <td>2015-04-01 02:00:00</td>\n",
       "      <td>4.874</td>\n",
       "      <td>45.785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34551849 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID            DateTime    lat     lon\n",
       "0         958  2015-03-18 18:00:00  4.888  45.740\n",
       "1         DEL  2015-03-04 18:00:00 -0.571  44.849\n",
       "2         DEL  2015-03-11 02:00:00  5.279  45.585\n",
       "3         404  2015-04-08 14:00:00  4.867  45.750\n",
       "4         488  2015-03-25 14:00:00  4.879  45.786\n",
       "...        ...                 ...    ...     ...\n",
       "34551844  229  2015-03-25 10:00:00  4.872  45.783\n",
       "34551845  424  2015-04-08 10:00:00  4.882  45.784\n",
       "34551846  719  2015-04-08 18:00:00  4.873  45.785\n",
       "34551847  335  2015-03-25 14:00:00  4.874  45.784\n",
       "34551848  719  2015-04-01 02:00:00  4.874  45.785\n",
       "\n",
       "[34551849 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anon_data = pd.read_csv(r\"anonimized_file.pkl\")\n",
    "anon_data = anon_data[['ID','DateTime','lon','lat']]\n",
    "anon_data.rename(columns={\"lat\": \"lon\", \"lon\": \"lat\"}, inplace=True)\n",
    "anon_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0963d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data['DateTime']= original_data['DateTime'].astype('datetime64[ns]')\n",
    "original_data['ID']= original_data['ID'].astype('string')\n",
    "anon_data['DateTime']= anon_data['DateTime'].astype('datetime64[ns]')\n",
    "anon_data['ID']= anon_data['ID'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1425863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_util(df_anon, df_original):\n",
    "    df_orig = df_original.copy()\n",
    "    df_anon = df_anon.copy()\n",
    "\n",
    "    df = pd.DataFrame({ 'df_hour': df_anon['DateTime'].dt.hour, 'df_origin_hour': df_orig['DateTime'].dt.hour })\n",
    "    #Chaque ligne vaut 1 point\n",
    "    #Une fraction de point eguale a 1/24 est enlevée à chaque heure d'écart\n",
    "    df['hour_util'] = 1- abs(df['df_hour'] - df['df_origin_hour'])/24\n",
    "    # le score finale est la moyenne d'ecart d'heures sur tous les points detecter\n",
    "    score_hour_utility = df[\"hour_util\"].sum()/len(df_orig)\n",
    "    \n",
    "    return score_hour_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d9312e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_util(df_anon, df_original):\n",
    "    df_orig = df_original.copy()\n",
    "    df_anon = df_anon.copy()\n",
    "\n",
    "    df_date_utility = pd.DataFrame({ 'DayOfTheWeek_orig': df_orig['DateTime'].dt.dayofweek, 'DayOfTheWeek_anon': df_anon['DateTime'].dt.dayofweek, 'Week_orig':df_orig['DateTime'].dt.isocalendar().week, 'Week_anon': df_anon['DateTime'].dt.isocalendar().week })\n",
    "    df_date_utility['DiffDate'] = abs(df_date_utility['DayOfTheWeek_orig']-df_date_utility['DayOfTheWeek_anon'])\n",
    "    #pour tout changement de semaine l'utilite doit etre 0 \n",
    "    df_date_utility.loc[~(df_date_utility['Week_orig']==df_date_utility['Week_anon']),'DiffDate']=7\n",
    "    df_date_utility['date_util']= 1- df_date_utility['DiffDate']/7\n",
    "\n",
    "    score = df_date_utility[\"date_util\"].mean().round(3)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7b1a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_util(df_anon, df_original):\n",
    "\n",
    "    df_orig = df_original.copy()\n",
    "    df_anon = df_anon.copy()\n",
    "    \n",
    "    df_anon.rename(columns={'ID':'ID_ano', 'DateTime':'DateTime_ano', 'lat':'lat_ano', 'lon':'lon_ano'}, inplace = True)\n",
    "    df = pd.concat([df_orig.reset_index(drop=True),df_anon.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    #Haversine distance\n",
    "    to_radians = np.pi /180\n",
    "    R = 6371.009 #en km\n",
    "    #a=np.sin(((df.lat*to_radians-df.lat_ano*to_radians)/2)**2) + np.sin((((df.lon*to_radians-df.lon_ano*to_radians)/2)**2))*np.cos(df.lat*to_radians)*np.cos(df.lat_ano*to_radians)\n",
    "    a = np.sin(((df.lat*to_radians-df.lat_ano*to_radians)/2))**2 + (np.sin((((df.lon*to_radians-df.lon_ano*to_radians)/2)))**(2))*np.cos(df.lat*to_radians)*np.cos(df.lat_ano*to_radians)\n",
    "    b = np.sqrt(a)\n",
    "    df['Haversine_score']= 2 * R * np.arcsin(b)\n",
    "    if(df[\"Haversine_score\"].mean().round(3)==0):\n",
    "        score = 1\n",
    "    else:\n",
    "        score = (1/(df[\"Haversine_score\"].mean())).round(3)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b5c88c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def POI_util(df_anon, df_original, params):\n",
    "    #Global variables\n",
    "    size = params['size']\n",
    "    values = ['NIGHT', 'NIGHT','WORK', 'WEEKEND']\n",
    "    df_orig = df_original.copy()\n",
    "    df_anon = df_anon.copy()\n",
    "    \n",
    "    df_orig['DateTime']= df_orig['DateTime'].astype('datetime64[ns]')\n",
    "    df_orig['ID']= df_orig['ID'].astype('string')\n",
    "    df_anon['DateTime']= df_anon['DateTime'].astype('datetime64[ns]')\n",
    "    df_anon['ID']= df_anon['ID'].astype('string')\n",
    "\n",
    "    #Pre-treatment of original dataframe\n",
    "    df_orig['lat']=df_orig['lat'].round(size)\n",
    "    df_orig['lon']=df_orig['lon'].round(size)\n",
    "    df_orig['Hour'] = df_orig.loc[:,'DateTime'].dt.hour\n",
    "    df_orig['Day'] = df_orig.loc[:,'DateTime'].dt.day\n",
    "    df_orig['Month'] = df_orig.loc[:,'DateTime'].dt.month\n",
    "    df_orig['Week'] = df_orig.loc[:,'DateTime'].dt.isocalendar().week\n",
    "    df_orig['DayOfTheWeek'] = df_orig.loc[:,'DateTime'].dt.dayofweek\n",
    "    df_orig.sort_values(by=['ID', 'DateTime'], inplace=True)\n",
    "    df_orig.reset_index(drop=True, inplace=True)\n",
    "    df_orig['DatetimeIndex'] = np.select(conditions(df_orig), values, 'RegularTime')\n",
    "    df_orig['time_spent']=0\n",
    "    \n",
    "    df_orig['Index_of_POI'] = df_orig['ID'] + '-' + df_orig['Day'].astype('string') + '-' + df_orig['Week'].astype('string') + '-' + df_orig['lat'].astype('string') + '-' + df_orig['lon'].astype('string') + '-' + df_orig['DatetimeIndex'].astype('string')\n",
    "    df_orig['Index_of_POI_shifted_backward'] = df_orig['Index_of_POI'].shift(-1)\n",
    "    df_orig['Index_of_POI_shifted_forward'] = df_orig['Index_of_POI'].shift(+1)\n",
    "    df_orig.loc[0,'Index_of_POI_shifted_forward']='0'\n",
    "    df_orig.loc[len(df_orig)-1,'Index_of_POI_shifted_backward']='0'\n",
    "    df_orig['start_time'] = df_orig.loc[~(df_orig['Index_of_POI']==df_orig['Index_of_POI_shifted_forward']), 'DateTime']\n",
    "    df_orig.fillna(method=\"ffill\", inplace=True) #propagate non-null values forward or backward\n",
    "    df_orig['time_spent'] = (df_orig['DateTime'] - df_orig['start_time'])#.dt.total_seconds()/60\n",
    "    \n",
    "    #Getting the POI\n",
    "    df_orig2 = df_orig.loc[~(df_orig['Index_of_POI_shifted_backward']==df_orig['Index_of_POI']),['ID', 'lat', 'lon', 'Week', 'DatetimeIndex', 'time_spent']].groupby(by=['ID', 'lat', 'lon', 'Week', 'DatetimeIndex']).sum().reset_index()\n",
    "    df_orig2 = df_orig2.sort_values(by=['ID', 'Week', 'time_spent',  'DatetimeIndex'], ascending=[True, True, False, False]).reset_index(drop=True)\n",
    "    df_orig2 = df_orig2.groupby(by=['ID', 'Week', 'DatetimeIndex']).head(1).reset_index(drop=True)\n",
    "\n",
    "    #Pre-treatment of anonymized dataframe\n",
    "    df_anon['ID_original']=df_orig.loc[:,'ID']\n",
    "    df_anon['lat']=df_orig['lat'].round(size)\n",
    "    df_anon['lon']=df_orig['lon'].round(size)\n",
    "    df_anon['Hour'] = df_anon.loc[:,'DateTime'].dt.hour\n",
    "    df_anon['Day'] = df_anon.loc[:,'DateTime'].dt.day\n",
    "    df_anon['Month'] = df_anon.loc[:,'DateTime'].dt.month\n",
    "    df_anon['Week'] = df_anon.loc[:,'DateTime'].dt.isocalendar().week\n",
    "    df_anon['DayOfTheWeek'] = df_anon.loc[:,'DateTime'].dt.dayofweek\n",
    "    df_anon['DatetimeIndex'] = np.select(conditions(df_anon), values, None)\n",
    "    df_anon.sort_values(by=['ID_original', 'DateTime'], inplace=True)\n",
    "    df_anon.reset_index(drop=True, inplace=True)\n",
    "    df_anon['time_spent']=0\n",
    "\n",
    "    # Creating the index\n",
    "    df_anon['Index_of_POI'] = df_anon['ID_original'] + '-' + df_anon['Day'].astype('string') + '-' + df_anon['Week'].astype('string') + '-' + df_anon['lat'].astype('string') + '-' + df_anon['lon'].astype('string') + '-' + df_anon['DatetimeIndex'].astype('string')\n",
    "    df_anon['Index_of_POI_shifted_backward'] = df_anon['Index_of_POI'].shift(-1)\n",
    "    df_anon['Index_of_POI_shifted_forward'] = df_anon['Index_of_POI'].shift(+1)\n",
    "    df_anon.loc[0,'Index_of_POI_shifted_forward']='0'\n",
    "    df_anon.loc[len(df_anon)-1,'Index_of_POI_shifted_backward']='0'\n",
    "\n",
    "    df_anon['start_time'] = df_anon.loc[~(df_anon['Index_of_POI']==df_anon['Index_of_POI_shifted_forward']), 'DateTime']\n",
    "    df_anon.fillna(method=\"ffill\", inplace=True) #propagate non-null values forward or backward\n",
    "    df_anon['time_spent'] = (df_anon['DateTime'] - df_anon['start_time'])#.dt.total_seconds()/60\n",
    "\n",
    "    df_anon2 = df_anon.loc[~(df_anon['Index_of_POI_shifted_backward']==df_anon['Index_of_POI']),['ID', 'lat', 'lon', 'Week', 'DatetimeIndex', 'time_spent']].groupby(by=['ID', 'lat', 'lon', 'Week', 'DatetimeIndex']).sum().reset_index()\n",
    "    df_anon2 = df_anon2.sort_values(by=['ID', 'Week', 'time_spent',  'DatetimeIndex'], ascending=[True, True, False, False]).reset_index(drop=True)\n",
    "\n",
    "    #Comparing the time spent in POI between original and anonymized dataset\n",
    "    left_join_df = pd.merge(df_orig2, df_anon2, on=['ID','lat','lon','Week','DatetimeIndex'], how='left')\n",
    "    left_join_df['time_spent_y'] = left_join_df['time_spent_y'].fillna(pd.Timedelta(seconds=0))\n",
    "    left_join_df.loc[left_join_df['time_spent_y']-left_join_df['time_spent_x'] == pd.Timedelta(0), 'diff_time_spent'] = 0\n",
    "    left_join_df.loc[~(left_join_df['time_spent_y']-left_join_df['time_spent_x'] == pd.Timedelta(0)), 'diff_time_spent'] = abs( (left_join_df.loc[left_join_df['time_spent_y']-left_join_df['time_spent_x'] > pd.Timedelta(0), 'time_spent_y'].dt.total_seconds()) - (left_join_df.loc[left_join_df['time_spent_y']-left_join_df['time_spent_x'] > pd.Timedelta(0), 'time_spent_x'].dt.total_seconds()) )\n",
    "    left_join_df.loc[left_join_df['time_spent_y'].dt.total_seconds()==0, 'diff_time_spent'] = left_join_df.loc[left_join_df['time_spent_y'].dt.total_seconds()==0, 'time_spent_x'].dt.total_seconds()\n",
    "    left_join_df = left_join_df.loc[~(left_join_df.DatetimeIndex =='RegularTime')]\n",
    "    \n",
    "    #Calculating the scrore\n",
    "    score = 1- (left_join_df['diff_time_spent'].sum()/left_join_df['time_spent_x'].dt.total_seconds().sum()) #.round(3)\n",
    "    return score\n",
    "\n",
    "def conditions(df):\n",
    "    return [\n",
    "        (df['DayOfTheWeek'] < 4) & (df['Hour']>=22) & (df['Hour']<=23), \n",
    "        (df['DayOfTheWeek'] < 4) & (df['Hour']>=0) & (df['Hour']<=6),\n",
    "        (df['DayOfTheWeek'] < 4) & (df['Hour']>=9) & (df['Hour']<=17),\n",
    "        (df['DayOfTheWeek'] >= 4) & (df['Hour']>=10) & (df['Hour']<=18)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d025b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
